log_level=info
client_id=realtime_ingestion

## Server to replicate from
replication_host=source_mysql
replication_password=maxwell
replication_port=3306
replication_user=max
# Every MySQL replicator has a unique 32-bit integer id
replica_server_id=12345

# Where to store captured schema and positions
host=source_mysql
user=max
password=maxwell
schema_database=maxwell_metadata

# Filter on which tables to ingest
filter= exclude: *.*, include: mysql_data.*


# Producer specific settings
producer=kafka
kafka.bootstrap.servers=kafka:19092
kafka_topic=cdc_%{database}_%{table}

# Configurations to apply on the kafka producer
kafka.acks=all
kafka.max.in.flight.requests.per.connection=1
kafka.delivery.timeout.ms=300000
kafka.retries=3
producer_partition_by=primary_key

# Should output DDL
output_ddl=true
ddl_kafka_topic=mysql_ddl


# What to output in the message
output_binlog_position=true
output_server_id=true
# The unique id of the client connection that generated the record in the source
output_thread_id=true
# Should include fields with NULL values
output_nulls=true
output_schema_id=true
# Transaction id (or commit info) helps to assemble records affected in the same transaction
output_commit_info=true


# Metrics to capture
metrics_type=jmx,http
metrics_prefix=MaxwellMetrics
metrics_jvm=false
http_port=8080
http_diagnostic=true
http_diagnostic_timeout=10000


# Should attempt master recovery
master_recovery=false
start_from_latest=false

# Shall we register the avro schema
register_avro_schema=false
kafka_schema_registry_url=http://localhost:8081
rds_namespace=real_time_analytics
# Where to send the notification if schema registration failed
slack_notification_url=https://slack.com/api/api.test